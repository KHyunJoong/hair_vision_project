import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from sklearn.model_selection import train_test_split
import time
import datetime
from torch.utils.data import DataLoader, TensorDataset
import os
import csv
import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import albumentations as A
from albumentations.pytorch import ToTensorV2
import numpy as np
import torch
from torch.utils.data import DataLoader, TensorDataset
import matplotlib.pyplot as plt
import random
#ì´ë¯¸ì§€ ìœ„ì¹˜ë³€ê²½ ë° íŒŒì¼ ì„¸íŒ…
#
# paths=[]
# for dirname, _, filenames in os.walk('./testdata'):
#     for filename in filenames:
#         paths+=[(os.path.join(dirname, filename))]
# print(paths)
# os.makedirs("./testdata/images", exist_ok=True)  # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ë¬´ì‹œ
# os.makedirs("./testdata/masks", exist_ok=True)
#
# for path in paths:
#     file = os.path.basename(path)  # íŒŒì¼ ì´ë¦„ë§Œ ì¶”ì¶œ
#     if file.startswith("mask"):
#         shutil.move(path, "./testdata/masks")  # íŒŒì¼ì„ masks í´ë”ë¡œ ì´ë™ (ì˜ë¼ë‚´ê¸°)
#     elif file.endswith(".png"):
#         shutil.move(path, "./testdata/images")  # íŒŒì¼ì„ images í´ë”ë¡œ ì´ë™ (ì˜ë¼ë‚´ê¸°)

#ìˆ˜ì •ì¤‘
# images_dir ='./testdata/images'
# masks_dir = './testdata/masks'
#
# images_listdir = sorted(os.listdir(images_dir))
# masks_listdir = sorted(os.listdir(masks_dir))
# N=list(range(9))
# random_N = N
#
# print(len(images_listdir))
# print(len(masks_listdir))
#
# image_size=512
# input_image_size=(512,512)
#
# def read_image(path):
#     img = cv2.imread(path)
#     img = cv2.resize(img, (image_size, image_size))
#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#     return img
#
# number=120
#
# MASKS=np.zeros((1,image_size, image_size, 1), dtype=bool)
# IMAGES=np.zeros((1,image_size, image_size, 3),dtype=np.uint8)
#
# for j,file in enumerate(images_listdir):   ##the smaller, the faster
#     try:
#         image = read_image(f"{images_dir}/{file}")
#         image_ex = np.expand_dims(image, axis=0)
#         IMAGES = np.vstack([IMAGES, image_ex])
#         mask = read_image(f"{masks_dir}/{masks_listdir[j]}")
#         mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
#         mask = mask.reshape(512,512,1)
#         mask_ex = np.expand_dims(mask, axis=0)
#         MASKS = np.vstack([MASKS, mask_ex])
#     except:
#         print(file)
#         continue
#
# images=np.array(IMAGES)[1:number+1]
# masks=np.array(MASKS)[1:number+1]
# print(images.shape,masks.shape)
#
# images_train, images_test, masks_train, masks_test = train_test_split(
#     images, masks, test_size=0.2, random_state=42)


class ConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ConvBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = F.relu(x)
        x = self.conv2(x)
        x = self.bn2(x)
        x = F.relu(x)
        return x

class EncoderBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(EncoderBlock, self).__init__()
        self.conv = ConvBlock(in_channels, out_channels)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

    def forward(self, x):
        skip = self.conv(x)
        pool = self.pool(skip)
        return skip, pool

class DecoderBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DecoderBlock, self).__init__()
        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)
        self.conv = ConvBlock(out_channels * 2, out_channels)

    def forward(self, x, skip):
        x = self.upconv(x)
        x = torch.cat([x, skip], dim=1)
        x = self.conv(x)
        return x

class UNet(nn.Module):
    def __init__(self, input_channels=3, output_channels=1):
        super(UNet, self).__init__()
        self.encoder1 = EncoderBlock(input_channels, 64)
        self.encoder2 = EncoderBlock(64, 128)
        self.encoder3 = EncoderBlock(128, 256)
        self.encoder4 = EncoderBlock(256, 512)

        self.bridge = ConvBlock(512, 1024)

        self.decoder1 = DecoderBlock(1024, 512)
        self.decoder2 = DecoderBlock(512, 256)
        self.decoder3 = DecoderBlock(256, 128)
        self.decoder4 = DecoderBlock(128, 64)

        self.final_conv = nn.Conv2d(64, output_channels, kernel_size=1)

    def forward(self, x):
        s1, p1 = self.encoder1(x)
        s2, p2 = self.encoder2(p1)
        s3, p3 = self.encoder3(p2)
        s4, p4 = self.encoder4(p3)

        b = self.bridge(p4)

        d1 = self.decoder1(b, s4)
        d2 = self.decoder2(d1, s3)
        d3 = self.decoder3(d2, s2)
        d4 = self.decoder4(d3, s1)

        outputs = torch.sigmoid(self.final_conv(d4))
        return outputs
def save_model(model,epochs,result_dir ):
    path=f"{result_dir}/unet_model_{epochs}.pth"
    torch.save(model.state_dict(), path)
    print(f"âœ… ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {path}")
def load_model(model, epochs,result_dir):
    path=f"{result_dir}/unet_model_{epochs}.pth"
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.load_state_dict(torch.load(path, map_location=device))
    model.to(device)
    print(f"âœ… ëª¨ë¸ì´ ë¶ˆëŸ¬ì™€ì¡ŒìŠµë‹ˆë‹¤: {path}")

class UNet_multi(nn.Module):
    def __init__(self, input_channels=3, output_channels=3):
        super(UNet, self).__init__()
        self.encoder1 = EncoderBlock(input_channels, 64)
        self.encoder2 = EncoderBlock(64, 128)
        self.encoder3 = EncoderBlock(128, 256)
        self.encoder4 = EncoderBlock(256, 512)

        self.bridge = ConvBlock(512, 1024)

        self.decoder1 = DecoderBlock(1024, 512)
        self.decoder2 = DecoderBlock(512, 256)
        self.decoder3 = DecoderBlock(256, 128)
        self.decoder4 = DecoderBlock(128, 64)

        self.final_conv = nn.Conv2d(64, output_channels, kernel_size=1)

    def forward(self, x):
        s1, p1 = self.encoder1(x)
        s2, p2 = self.encoder2(p1)
        s3, p3 = self.encoder3(p2)
        s4, p4 = self.encoder4(p3)

        b = self.bridge(p4)

        d1 = self.decoder1(b, s4)
        d2 = self.decoder2(d1, s3)
        d3 = self.decoder3(d2, s2)
        d4 = self.decoder4(d3, s1)

        outputs = torch.softmax(self.final_conv(d4), dim=1)  # âœ… softmax ì ìš©
        return outputs

# ëª¨ë¸ ìƒì„± ë° í…ŒìŠ¤íŠ¸
# model = UNet(input_channels=3, output_channels=1)
# print(model)
def load_data(images_dir, masks_dir, image_size=512, test_size=0.2, val_size=0.2):
    """
    ì´ë¯¸ì§€ ë° ë§ˆìŠ¤í¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , Train/Validation/Test ë°ì´í„°ë¡œ ë¶„í• í•˜ëŠ” í•¨ìˆ˜

    Args:
        images_dir (str): ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
        masks_dir (str): ë§ˆìŠ¤í¬ í´ë” ê²½ë¡œ
        image_size (int, optional): ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸ê°’: 512)
        test_size (float, optional): Test ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2)
        val_size (float, optional): Train ë°ì´í„°ì—ì„œ Validation ë°ì´í„°ë¡œ ì‚¬ìš©í•  ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2)

    Returns:
        Tuple: (images_train, images_val, images_test, masks_train, masks_val, masks_test)
    """
    images_listdir = sorted(os.listdir(images_dir))
    masks_listdir = sorted(os.listdir(masks_dir))

    print(f"ì´ ì´ë¯¸ì§€ ê°œìˆ˜: {len(images_listdir)}")
    print(f"ì´ ë§ˆìŠ¤í¬ ê°œìˆ˜: {len(masks_listdir)}")

    # ì´ë¯¸ì§€ ë° ë§ˆìŠ¤í¬ ë°ì´í„° ë¡œë“œ
    images, masks = [], []
    for j, file in enumerate(images_listdir):
        try:
            image = cv2.imread(os.path.join(images_dir, file))
            image = cv2.resize(image, (image_size, image_size))
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # RGB ë³€í™˜
            images.append(image)

            mask = cv2.imread(os.path.join(masks_dir, masks_listdir[j]), cv2.IMREAD_GRAYSCALE)
            mask = cv2.resize(mask, (image_size, image_size))
            mask = np.expand_dims(mask, axis=-1)  # (H, W) â†’ (H, W, 1)
            mask = (mask > 127).astype(np.uint8)  # Threshold ì ìš©í•˜ì—¬ 0ê³¼ 1ë¡œ ë³€í™˜
            masks.append(mask)

        except Exception as e:
            print(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {file} - {e}")
            continue

    images = np.array(images, dtype=np.uint8)
    masks = np.array(masks, dtype=np.uint8)

    print(f"ë¡œë“œëœ ì´ë¯¸ì§€ í˜•íƒœ: {images.shape}, ë§ˆìŠ¤í¬ í˜•íƒœ: {masks.shape}")

    # âœ… Train/Test Split (Test ë°ì´í„° ë¨¼ì € ë¶„ë¦¬)
    images_train_full, images_test, masks_train_full, masks_test = train_test_split(
        images, masks, test_size=test_size, random_state=42
    )

    # âœ… Train/Validation Split (Train ë°ì´í„°ì—ì„œ Validation ë¶„ë¦¬)
    images_train, images_val, masks_train, masks_val = train_test_split(
        images_train_full, masks_train_full, test_size=val_size, random_state=42
    )

    print(f"Train: {images_train_full.shape}, Validation: {images_val.shape}, Test: {images_test.shape}")
    return images_train_full, images_val, images_test, masks_train_full, masks_val, masks_test
import os
import cv2
import numpy as np
from sklearn.model_selection import train_test_split

def load_data_multi(images_dir, masks_dir, image_size=512, test_size=0.2, val_size=0.2):
    """
    ì´ë¯¸ì§€ ë° ë§ˆìŠ¤í¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , Train/Validation/Test ë°ì´í„°ë¡œ ë¶„í• í•˜ëŠ” í•¨ìˆ˜

    Args:
        images_dir (str): ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
        masks_dir (str): ë§ˆìŠ¤í¬ í´ë” ê²½ë¡œ
        image_size (int, optional): ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸ê°’: 512)
        test_size (float, optional): Test ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2)
        val_size (float, optional): Train ë°ì´í„°ì—ì„œ Validation ë°ì´í„°ë¡œ ì‚¬ìš©í•  ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2)

    Returns:
        Tuple: (images_train, images_val, images_test, masks_train, masks_val, masks_test)
    """
    images_listdir = sorted(os.listdir(images_dir))
    masks_listdir = sorted(os.listdir(masks_dir))

    print(f"ì´ ì´ë¯¸ì§€ ê°œìˆ˜: {len(images_listdir)}")
    print(f"ì´ ë§ˆìŠ¤í¬ ê°œìˆ˜: {len(masks_listdir)}")

    # ì´ë¯¸ì§€ ë° ë§ˆìŠ¤í¬ ë°ì´í„° ë¡œë“œ
    images, masks = [], []
    for j, file in enumerate(images_listdir):
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = cv2.imread(os.path.join(images_dir, file))
            image = cv2.resize(image, (image_size, image_size))
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # RGB ë³€í™˜
            images.append(image)

            # ë§ˆìŠ¤í¬ ë¡œë“œ (Grayscale)
            mask = cv2.imread(os.path.join(masks_dir, masks_listdir[j]), cv2.IMREAD_GRAYSCALE)
            print("mask",np.unique(mask))
            mask = cv2.resize(mask, (image_size, image_size), interpolation=cv2.INTER_NEAREST)
            print("mask",np.unique(mask))
            # âœ… Multi-Class Mask ë³€í™˜ (0, 1, 2)
            mask[mask == 255] = 2  # í°ìƒ‰ â†’ í´ë˜ìŠ¤ 2
            mask[mask == 128] = 1  # íšŒìƒ‰ â†’ í´ë˜ìŠ¤ 1
            mask[mask == 0] = 0    # ê²€ì€ìƒ‰ â†’ í´ë˜ìŠ¤ 0

            # (H, W) â†’ (H, W, 1)ë¡œ ì°¨ì› í™•ì¥
            mask = np.expand_dims(mask, axis=-1)
            masks.append(mask)

        except Exception as e:
            print(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {file} - {e}")
            continue

    images = np.array(images, dtype=np.uint8)
    masks = np.array(masks, dtype=np.uint8)

    print(f"ë¡œë“œëœ ì´ë¯¸ì§€ í˜•íƒœ: {images.shape}, ë§ˆìŠ¤í¬ í˜•íƒœ: {masks.shape}")

    # âœ… Train/Test Split (Test ë°ì´í„° ë¨¼ì € ë¶„ë¦¬)
    images_train_full, images_test, masks_train_full, masks_test = train_test_split(
        images, masks, test_size=test_size, random_state=42
    )

    # âœ… Train/Validation Split (Train ë°ì´í„°ì—ì„œ Validation ë¶„ë¦¬)
    images_train, images_val, masks_train, masks_val = train_test_split(
        images_train_full, masks_train_full, test_size=val_size, random_state=42
    )

    print(f"Train: {images_train.shape}, Validation: {images_val.shape}, Test: {images_test.shape}")
    return images_train, images_val, images_test, masks_train, masks_val, masks_test

# âœ… Augmentation ì„¤ì • í•¨ìˆ˜ (ì¼œê³  ëŒ ìˆ˜ ìˆë„ë¡ ì„¤ì •)
def get_augmentation(apply_augmentation=True):
    """
    Augmentationì„ ì ìš©í• ì§€ ì—¬ë¶€ì— ë”°ë¼ ë³€í™˜ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

    Args:
        apply_augmentation (bool): Augmentation ì ìš© ì—¬ë¶€ (True: ì ìš©, False: ë¯¸ì ìš©)

    Returns:
        albumentations.Compose: Augmentation ë³€í™˜ ê°ì²´
    """
    if apply_augmentation:
        return A.Compose([
            A.HorizontalFlip(p=0.5),  # ì¢Œìš° ë°˜ì „ (50% í™•ë¥ )
            A.VerticalFlip(p=0.3),  # ìƒí•˜ ë°˜ì „ (30% í™•ë¥ )
            A.RandomRotate90(p=0.5),  # 90ë„ íšŒì „ (50% í™•ë¥ )
            A.RandomBrightnessContrast(p=0.2),  # ë°ê¸° & ëŒ€ë¹„ ì¡°ì • (20% í™•ë¥ )
            A.GaussianBlur(p=0.2),  # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ (20% í™•ë¥ )
            A.ElasticTransform(p=0.2, alpha=1, sigma=50, approximate=True),  # íƒ„ì„± ë³€í˜• (20% í™•ë¥ )
            A.Resize(512, 512),  # í¬ê¸° ì¡°ì • (ëª¨ë“  ì´ë¯¸ì§€ 512x512ë¡œ í†µì¼)
        ])
    else:
        return A.Compose([
            A.Resize(512, 512),  # í¬ê¸° ì¡°ì •ë§Œ ì ìš© (Augmentation ë¯¸ì ìš©)
        ])

# âœ… Augmentationì„ ì ìš©í•˜ëŠ” í•¨ìˆ˜ (True / Falseë¡œ ì„¤ì •)
def apply_augmentation(images, masks, apply_aug=True, augmentation_factor=10):
    """
    Augmentation ì ìš© ì—¬ë¶€ì— ë”°ë¼ ë°ì´í„°ë¥¼ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜

    Args:
        images (numpy.ndarray): ì›ë³¸ ì´ë¯¸ì§€ ë°°ì—´ (H, W, C)
        masks (numpy.ndarray): ì›ë³¸ ë§ˆìŠ¤í¬ ë°°ì—´ (H, W, 1)
        apply_aug (bool): Augmentation ì ìš© ì—¬ë¶€ (True: ì ìš©, False: ë¯¸ì ìš©)

    Returns:
        numpy.ndarray: Augmentationì´ ì ìš©ëœ ì´ë¯¸ì§€ ë° ë§ˆìŠ¤í¬
    """
    transform = get_augmentation(apply_aug)
    augmented_images, augmented_masks = [], []
    if apply_aug:
        print('aug_T')
        for img, mask in zip(images, masks):
            augmented_images.append(img)  # ì›ë³¸ ì¶”ê°€
            augmented_masks.append(mask)

            for _ in range(augmentation_factor - 1):  # âœ… Në°° ì¦ê°•
                augmented = transform(image=img, mask=mask)
                augmented_images.append(augmented['image'])
                augmented_masks.append(augmented['mask'])

        return np.array(augmented_images), np.array(augmented_masks)
    else:
        print('aug_F')
        return  images, masks


# âœ… Augmentation ì ìš© í›„ ì‹œê°í™” í•¨ìˆ˜
def visualize_augmentation(images, masks, apply_aug=True, num_samples=3):
    fig, axs = plt.subplots(num_samples, 4, figsize=(15, 5 * num_samples))

    # âœ… Augmentation ì ìš© ì—¬ë¶€ ì„ íƒ (í•¨ìˆ˜ì™€ ì¶©ëŒ ë°©ì§€)
    images_aug, masks_aug = apply_augmentation(images, masks, apply_aug)

    for i in range(num_samples):
        idx = random.randint(0, len(images) - 1)

        # ì›ë³¸ ë° ì¦ê°•ëœ ì´ë¯¸ì§€ ë° ë§ˆìŠ¤í¬ ê°€ì ¸ì˜¤ê¸°
        original_image = images[idx]
        original_mask = masks[idx]
        transformed_image = images_aug[idx]
        transformed_mask = masks_aug[idx]

        axs[i, 0].imshow(original_image)
        axs[i, 0].set_title("Original Image")
        axs[i, 0].axis("off")

        axs[i, 1].imshow(transformed_image)
        axs[i, 1].set_title("Augmented Image" if apply_augmentation else "Resized Image")
        axs[i, 1].axis("off")

        axs[i, 2].imshow(original_mask, cmap="gray")
        axs[i, 2].set_title("Original Mask")
        axs[i, 2].axis("off")

        axs[i, 3].imshow(transformed_mask, cmap="gray")
        axs[i, 3].set_title("Augmented Mask" if apply_augmentation else "Resized Mask")
        axs[i, 3].axis("off")

    plt.show()

# âœ… Train DataLoader ìƒì„± í•¨ìˆ˜
# âœ… Train DataLoader ìƒì„± í•¨ìˆ˜ (Augmentation On/Off ê°€ëŠ¥)
# def train_data_load(images_train, masks_train, batch_size, apply_aug=False, augmentation_factor=10):
#     """
#     Train ë°ì´í„°ë¥¼ Augmentation í›„ PyTorch DataLoaderë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
#
#     Args:
#         images_train (numpy.ndarray): í•™ìŠµ ì´ë¯¸ì§€ (HWC í˜•ì‹)
#         masks_train (numpy.ndarray): í•™ìŠµ ë§ˆìŠ¤í¬ (HWC í˜•ì‹)
#         batch_size (int): ë°°ì¹˜ í¬ê¸°
#         apply_aug (bool): Augmentation ì ìš© ì—¬ë¶€ (True: ì ìš©, False: ë¯¸ì ìš©)
#         augmentation_factor (int): Augmentation ì ìš© ì‹œ ëª‡ ë°°ë¡œ ì¦ê°•í• ì§€ ì„¤ì •
#
#     Returns:
#         DataLoader: PyTorch DataLoader ê°ì²´
#     """
#     # âœ… ì¦ê°• ì „ ë°ì´í„° í¬ê¸° í™•ì¸
#     print(f"ğŸ”¹ Augmentation ì „ ë°ì´í„° í¬ê¸°: images = {images_train.shape}, masks = {masks_train.shape}")
#
#     # âœ… Train DataLoader ìƒì„± í•¨ìˆ˜ (Augmentation On/Off ê°€ëŠ¥)
#     images_train_aug, masks_train_aug = apply_augmentation(images_train, masks_train, apply_aug, augmentation_factor)
#
#     # âœ… ì¦ê°• í›„ ë°ì´í„° í¬ê¸° í™•ì¸
#     print(f"âœ… Augmentation ì ìš© í›„ ë°ì´í„° í¬ê¸°: images = {images_train_aug.shape}, masks = {masks_train_aug.shape}")
#
#     # PyTorch Tensor ë³€í™˜
#     images_train_torch = torch.tensor(images_train_aug, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0
#     masks_train_torch = torch.tensor(masks_train_aug, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0  # ì •ê·œí™”
#
#     train_dataset = TensorDataset(images_train_torch, masks_train_torch)
#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
#
#     return train_loader


def train_data_load(images_train, masks_train, batch_size, apply_aug=False, augmentation_factor=10):
    """
    Train ë°ì´í„°ë¥¼ Augmentation í›„ PyTorch DataLoaderë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜

    Args:
        images_train (numpy.ndarray): í•™ìŠµ ì´ë¯¸ì§€ (HWC í˜•ì‹)
        masks_train (numpy.ndarray): í•™ìŠµ ë§ˆìŠ¤í¬ (HWC í˜•ì‹)
        batch_size (int): ë°°ì¹˜ í¬ê¸°
        apply_aug (bool): Augmentation ì ìš© ì—¬ë¶€ (True: ì ìš©, False: ë¯¸ì ìš©)
        augmentation_factor (int): Augmentation ì ìš© ì‹œ ëª‡ ë°°ë¡œ ì¦ê°•í• ì§€ ì„¤ì •

    Returns:
        DataLoader: PyTorch DataLoader ê°ì²´
    """
    # âœ… ì¦ê°• ì „ ë°ì´í„° í¬ê¸° í™•ì¸
    print(f"ğŸ”¹ Augmentation ì „ ë°ì´í„° í¬ê¸°: images = {images_train.shape}, masks = {masks_train.shape}")

    # âœ… ë§ˆìŠ¤í¬ ê°’ ë²”ìœ„ í™•ì¸ (ì •ê·œí™” í•„ìš” ì—¬ë¶€ í™•ì¸)
    print(f"ğŸ” ë§ˆìŠ¤í¬ ë°ì´í„° ìµœì†Œê°’: {masks_train.min()}, ìµœëŒ€ê°’: {masks_train.max()}")

    # âœ… Train DataLoader ìƒì„± í•¨ìˆ˜ (Augmentation On/Off ê°€ëŠ¥)
    images_train_aug, masks_train_aug = apply_augmentation(images_train, masks_train, apply_aug, augmentation_factor)

    # âœ… ì¦ê°• í›„ ë°ì´í„° í¬ê¸° í™•ì¸
    print(f"âœ… Augmentation ì ìš© í›„ ë°ì´í„° í¬ê¸°: images = {images_train_aug.shape}, masks = {masks_train_aug.shape}")

    # âœ… Augmentation í›„ ë§ˆìŠ¤í¬ ê°’ ë²”ìœ„ í™•ì¸ (ë°˜ì „ ì—¬ë¶€ ì²´í¬)
    print(f"ğŸ” ì¦ê°• í›„ ë§ˆìŠ¤í¬ ë°ì´í„° ìµœì†Œê°’: {masks_train_aug.min()}, ìµœëŒ€ê°’: {masks_train_aug.max()}")

    # PyTorch Tensor ë³€í™˜
    images_train_torch = torch.tensor(images_train_aug, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0
    masks_train_torch = torch.tensor(masks_train_aug, dtype=torch.float32).permute(0, 3, 1, 2)   # ì •ê·œí™”

    # âœ… PyTorch Tensor ë³€í™˜ í›„ ë§ˆìŠ¤í¬ ê°’ ë²”ìœ„ í™•ì¸
    print(f"ğŸ›  ë³€í™˜ í›„ ë§ˆìŠ¤í¬ ìµœì†Œê°’: {masks_train_torch.min()}, ìµœëŒ€ê°’: {masks_train_torch.max()}")

    train_dataset = TensorDataset(images_train_torch, masks_train_torch)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    return train_loader



# âœ… Validation DataLoader ìƒì„± í•¨ìˆ˜ (Augmentation On/Off ê°€ëŠ¥)
# âœ… Validation DataLoader ìƒì„± í•¨ìˆ˜ (Augmentation On/Off ê°€ëŠ¥)
def val_data_load(images_val, masks_val, batch_size, apply_aug=False, augmentation_factor=1):
    """
    Validation ë°ì´í„°ë¥¼ Augmentation í›„ PyTorch DataLoaderë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜

    Args:
        images_val (numpy.ndarray): ê²€ì¦ ì´ë¯¸ì§€ (HWC í˜•ì‹)
        masks_val (numpy.ndarray): ê²€ì¦ ë§ˆìŠ¤í¬ (HWC í˜•ì‹)
        batch_size (int): ë°°ì¹˜ í¬ê¸°
        apply_aug (bool): Augmentation ì ìš© ì—¬ë¶€ (True: ì ìš©, False: ë¯¸ì ìš©)
        augmentation_factor (int): ì¦ê°• íšŸìˆ˜ (Validationì—ëŠ” ê¸°ë³¸ê°’ 1)

    Returns:
        DataLoader: PyTorch DataLoader ê°ì²´
    """
    # Augmentation ì ìš© ì—¬ë¶€ ì„ íƒ
    images_val_aug, masks_val_aug = apply_augmentation(images_val, masks_val, apply_aug, augmentation_factor)

    # PyTorch Tensor ë³€í™˜
    images_val_torch = torch.tensor(images_val_aug, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0
    masks_val_torch = torch.tensor(masks_val_aug, dtype=torch.float32).permute(0, 3, 1, 2)   # ì •ê·œí™”

    print("Validation Masks min/max:", masks_val_torch.min().item(), masks_val_torch.max().item())

    val_dataset = TensorDataset(images_val_torch, masks_val_torch)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # ê²€ì¦ ë°ì´í„°ëŠ” ì¼ë°˜ì ìœ¼ë¡œ shuffle=False
    return val_loader

def train_data_load_multi(images_train, masks_train, batch_size, apply_aug=False, augmentation_factor=10):
    """
    Train ë°ì´í„°ë¥¼ Augmentation í›„ PyTorch DataLoaderë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜

    Args:
        images_train (numpy.ndarray): í•™ìŠµ ì´ë¯¸ì§€ (HWC í˜•ì‹)
        masks_train (numpy.ndarray): í•™ìŠµ ë§ˆìŠ¤í¬ (HWC í˜•ì‹)
        batch_size (int): ë°°ì¹˜ í¬ê¸°
        apply_aug (bool): Augmentation ì ìš© ì—¬ë¶€ (True: ì ìš©, False: ë¯¸ì ìš©)
        augmentation_factor (int): Augmentation ì ìš© ì‹œ ëª‡ ë°°ë¡œ ì¦ê°•í• ì§€ ì„¤ì •

    Returns:
        DataLoader: PyTorch DataLoader ê°ì²´
    """
    # âœ… ì¦ê°• ì „ ë°ì´í„° í¬ê¸° í™•ì¸
    print(f"ğŸ”¹ Augmentation ì „ ë°ì´í„° í¬ê¸°: images = {images_train.shape}, masks = {masks_train.shape}")

    # âœ… ë§ˆìŠ¤í¬ ê°’ ë²”ìœ„ í™•ì¸ (ì •ê·œí™” í•„ìš” ì—¬ë¶€ í™•ì¸)
    print(f"ğŸ” ë§ˆìŠ¤í¬ ë°ì´í„° ìµœì†Œê°’: {masks_train.min()}, ìµœëŒ€ê°’: {masks_train.max()}")

    # âœ… Train DataLoader ìƒì„± í•¨ìˆ˜ (Augmentation On/Off ê°€ëŠ¥)
    images_train_aug, masks_train_aug = apply_augmentation(images_train, masks_train, apply_aug, augmentation_factor)

    # âœ… ì¦ê°• í›„ ë°ì´í„° í¬ê¸° í™•ì¸
    print(f"âœ… Augmentation ì ìš© í›„ ë°ì´í„° í¬ê¸°: images = {images_train_aug.shape}, masks = {masks_train_aug.shape}")

    # âœ… Augmentation í›„ ë§ˆìŠ¤í¬ ê°’ ë²”ìœ„ í™•ì¸ (ë°˜ì „ ì—¬ë¶€ ì²´í¬)
    print(f"ğŸ” ì¦ê°• í›„ ë§ˆìŠ¤í¬ ë°ì´í„° ìµœì†Œê°’: {masks_train_aug.min()}, ìµœëŒ€ê°’: {masks_train_aug.max()}")

    # PyTorch Tensor ë³€í™˜
    images_train_torch = torch.tensor(images_train_aug, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0
    masks_train_torch = torch.tensor(masks_train_aug, dtype=torch.float32).permute(0, 3, 1, 2) /masks_train_aug.max() # ì •ê·œí™”

    # âœ… PyTorch Tensor ë³€í™˜ í›„ ë§ˆìŠ¤í¬ ê°’ ë²”ìœ„ í™•ì¸
    print(f"ğŸ›  ë³€í™˜ í›„ ë§ˆìŠ¤í¬ ìµœì†Œê°’: {masks_train_torch.min()}, ìµœëŒ€ê°’: {masks_train_torch.max()}")

    train_dataset = TensorDataset(images_train_torch, masks_train_torch)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    return train_loader



# âœ… Validation DataLoader ìƒì„± í•¨ìˆ˜ (Augmentation On/Off ê°€ëŠ¥)
# âœ… Validation DataLoader ìƒì„± í•¨ìˆ˜ (Augmentation On/Off ê°€ëŠ¥)
def val_data_load_multi(images_val, masks_val, batch_size, apply_aug=False, augmentation_factor=1):
    """
    Validation ë°ì´í„°ë¥¼ Augmentation í›„ PyTorch DataLoaderë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜

    Args:
        images_val (numpy.ndarray): ê²€ì¦ ì´ë¯¸ì§€ (HWC í˜•ì‹)
        masks_val (numpy.ndarray): ê²€ì¦ ë§ˆìŠ¤í¬ (HWC í˜•ì‹)
        batch_size (int): ë°°ì¹˜ í¬ê¸°
        apply_aug (bool): Augmentation ì ìš© ì—¬ë¶€ (True: ì ìš©, False: ë¯¸ì ìš©)
        augmentation_factor (int): ì¦ê°• íšŸìˆ˜ (Validationì—ëŠ” ê¸°ë³¸ê°’ 1)

    Returns:
        DataLoader: PyTorch DataLoader ê°ì²´
    """
    # Augmentation ì ìš© ì—¬ë¶€ ì„ íƒ
    images_val_aug, masks_val_aug = apply_augmentation(images_val, masks_val, apply_aug, augmentation_factor)

    # PyTorch Tensor ë³€í™˜
    images_val_torch = torch.tensor(images_val_aug, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0
    masks_val_torch = torch.tensor(masks_val_aug, dtype=torch.float32).permute(0, 3, 1, 2) /masks_val_aug.max()  # ì •ê·œí™”

    print("Validation Masks min/max:", masks_val_torch.min().item(), masks_val_torch.max().item())

    val_dataset = TensorDataset(images_val_torch, masks_val_torch)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # ê²€ì¦ ë°ì´í„°ëŠ” ì¼ë°˜ì ìœ¼ë¡œ shuffle=False
    return val_loader
# # ë°ì´í„° ë³€í™˜ (0~255 ê°’ì„ 0~1ë¡œ ì •ê·œí™”)
# def train_data_load(images_train, masks_train, batch_size):
#     images_train_torch = torch.tensor(images_train, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0
#     masks_train_torch = torch.tensor(masks_train, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0  # âœ… ë§ˆìŠ¤í¬ë„ ì •ê·œí™”
#
#     # ë§ˆìŠ¤í¬ ê°’ì´ 0~1 ì‚¬ì´ì¸ì§€ í™•ì¸
#     print("Masks min/max:", masks_train_torch.min().item(), masks_train_torch.max().item())
#
#     # PyTorch DataLoader ì„¤ì •
#     train_dataset = TensorDataset(images_train_torch, masks_train_torch)
#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
#     return train_loader
# def val_data_load(images_train, masks_train, batch_size):
#     images_val_torch = torch.tensor(images_val, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0
#     masks_val_torch = torch.tensor(masks_val, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0  # âœ… ë§ˆìŠ¤í¬ë„ ì •ê·œí™”
#
#     # ë§ˆìŠ¤í¬ ê°’ì´ 0~1 ì‚¬ì´ì¸ì§€ í™•ì¸
#     print("Masks min/max:", masks_val_torch.min().item(), masks_val_torch.max().item())
#
#     # PyTorch DataLoader ì„¤ì •
#     val_dataset = TensorDataset(images_val_torch, masks_val_torch)
#     val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)
#     return train_loader
def compute_iou(preds, targets, threshold=0.5):
    preds = (preds > threshold).float()
    intersection = (preds * targets).sum()
    union = preds.sum() + targets.sum() - intersection
    return (intersection / union).item() if union > 0 else 1.0

def compute_dice(preds, targets, threshold=0.5):
    preds = (preds > threshold).float()
    intersection = (preds * targets).sum()
    return (2. * intersection / (preds.sum() + targets.sum())).item() if (preds.sum() + targets.sum()) > 0 else 1.0

def model_train(train_data, val_data, epochs, learning_rate,log_file,result_dir):
    # Hyperparameters
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = UNet(input_channels=3, output_channels=1).to(device)
    criterion = nn.BCELoss()  # ë°”ì´ë„ˆë¦¬ í¬ë¡œìŠ¤ì—”íŠ¸ë¡œí”¼
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # CSV íŒŒì¼ë¡œ ë¡œê¹…
    with open(log_file, mode='a', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["Epoch", "Train Loss", "Validation Loss", "IoU", "Dice Score", "Time (s)", "Learning Rate", "GPU Memory (MB)"])

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        start_time = time.perf_counter()

        for images, masks in train_data:
            images, masks = images.to(device), masks.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, masks)  # âœ… masks ê°’ì´ 0~1 ë²”ìœ„ì—¬ì•¼ í•¨
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        avg_train_loss = running_loss / len(train_data)

        # âœ… Validation ê³¼ì • ì¶”ê°€
        model.eval()
        val_loss = 0.0
        iou_scores = []
        dice_scores = []

        with torch.no_grad():
            for images, masks in val_data:
                images, masks = images.to(device), masks.to(device)
                outputs = model(images)
                loss = criterion(outputs, masks)
                val_loss += loss.item()

                # IoU, Dice Score ê³„ì‚°
                iou = compute_iou(outputs, masks)
                dice = compute_dice(outputs, masks)
                iou_scores.append(iou)
                dice_scores.append(dice)

        avg_val_loss = val_loss / len(val_data)
        avg_iou = np.mean(iou_scores)
        avg_dice = np.mean(dice_scores)
        elapsed_time = time.perf_counter() - start_time
        current_lr = optimizer.param_groups[0]['lr']
        gpu_memory = torch.cuda.memory_allocated(device) / 1024 ** 2  # MB ë‹¨ìœ„

        # ë¡œê·¸ ê¸°ë¡
        with open(log_file, mode='a', newline='') as file:
            writer = csv.writer(file)
            writer.writerow([epoch+1, avg_train_loss, avg_val_loss, avg_iou, avg_dice, elapsed_time, current_lr, gpu_memory])

        print(f"Epoch [{epoch+1}/{epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | IoU: {avg_iou:.4f} | Dice: {avg_dice:.4f} | Time: {elapsed_time:.2f}s | LR: {current_lr:.6f} | GPU: {gpu_memory:.2f}MB")

    save_model(model, epochs,result_dir)
    print("Model saved!")
    print("Training complete!")


def model_train_3(train_data, val_data, epochs, learning_rate, log_file, result_dir):
    # Hyperparameters
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = UNet(input_channels=3, output_channels=3).to(device)  # âœ… ì¶œë ¥ ì±„ë„ 3ê°œë¡œ ë³€ê²½
    criterion = nn.CrossEntropyLoss()  # âœ… ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì†ì‹¤ í•¨ìˆ˜
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # CSV íŒŒì¼ë¡œ ë¡œê¹…
    with open(log_file, mode='a', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["Epoch", "Train Loss", "Validation Loss", "IoU", "Dice Score", "Time (s)", "Learning Rate", "GPU Memory (MB)"])

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        start_time = time.perf_counter()

        for images, masks in train_data:
            images = images.clone().detach().to(device, dtype=torch.float32)  # âœ… ëª¨ë¸ ì…ë ¥ float32 ë³€í™˜
            masks = masks.clone().detach().to(device, dtype=torch.long)  # âœ… ë§ˆìŠ¤í¬ ì •ìˆ˜í˜• ë³€í™˜

            # ë””ë²„ê¹… ì¶œë ¥
            # print("ë³€í™˜ ì „ masks.shape:", masks.shape)  # (batch, 1, H, W) ë˜ëŠ” (batch, H, W)

            masks = masks.squeeze(1)  # âœ… ë‹¤ì‹œ í•œ ë²ˆ squeeze ì ìš© (í™•ì‹¤íˆ ë³€í™˜)

            # print("ë³€í™˜ í›„ masks.shape:", masks.shape)  # (batch, H, W)ë¡œ ë³€ê²½ë˜ì–´ì•¼ í•¨

            outputs = model(images)  # ëª¨ë¸ ì‹¤í–‰
            # print("âœ… outputs.shape:", outputs.shape)  # (batch, num_classes, H, W) í™•ì¸

            loss = criterion(outputs, masks)  # âœ… CrossEntropyLoss ì‚¬ìš©
            loss.backward()
            optimizer.step()


            running_loss += loss.item()
            # print("masks.shape before squeeze:", masks.shape)
            masks = masks.squeeze(1)  # âœ… 1ì±„ë„ ì œê±°
            # print("masks.shape after squeeze:", masks.shape)

            # ë°ì´í„° íƒ€ì… í™•ì¸
            # print("âœ… masks.dtype:", masks.dtype)  # ë°˜ë“œì‹œ torch.longì´ì–´ì•¼ í•¨
        avg_train_loss = running_loss / len(train_data)


        # âœ… Validation ê³¼ì • ì¶”ê°€
        model.eval()
        val_loss = 0.0
        iou_scores = []
        dice_scores = []

        with torch.no_grad():
            for images, masks in val_data:
                images = images.to(device)
                masks = masks.to(device, dtype=torch.long).squeeze(1)  # âœ… ë§ˆìŠ¤í¬ ì°¨ì› ì¤„ì´ê¸°

                # âœ… One-hot Encoding ë³€í™˜ (CrossEntropyLossë¥¼ ì‚¬ìš©í•  ê²½ìš° í•„ìš”í•  ìˆ˜ë„ ìˆìŒ)
                masks = torch.nn.functional.one_hot(masks, num_classes=3).permute(0, 3, 1, 2).float()

                # ë””ë²„ê¹… ì¶œë ¥
                # print("âœ… outputs.shape:", outputs.shape)  # (batch, 3, H, W)
                # print("âœ… masks.shape after one-hot:", masks.shape)  # (batch, 3, H, W)

                outputs = model(images)  # ëª¨ë¸ ì‹¤í–‰
                loss = criterion(outputs, masks)  # âœ… CrossEntropyLoss ì ìš©
                val_loss += loss.item()

                # IoU, Dice Score ê³„ì‚°
                iou = compute_iou(outputs, masks)
                dice = compute_dice(outputs, masks)
                iou_scores.append(iou)
                dice_scores.append(dice)


        avg_val_loss = val_loss / len(val_data)
        avg_iou = np.mean(iou_scores)
        avg_dice = np.mean(dice_scores)
        elapsed_time = time.perf_counter() - start_time
        current_lr = optimizer.param_groups[0]['lr']
        gpu_memory = torch.cuda.memory_allocated(device) / 1024 ** 2  # MB ë‹¨ìœ„

        # ë¡œê·¸ ê¸°ë¡
        with open(log_file, mode='a', newline='') as file:
            writer = csv.writer(file)
            writer.writerow([epoch+1, avg_train_loss, avg_val_loss, avg_iou, avg_dice, elapsed_time, current_lr, gpu_memory])

        print(f"Epoch [{epoch+1}/{epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | IoU: {avg_iou:.4f} | Dice: {avg_dice:.4f} | Time: {elapsed_time:.2f}s | LR: {current_lr:.6f} | GPU: {gpu_memory:.2f}MB")

    save_model(model, epochs, result_dir)
    print("Model saved!")
    print("Training complete!")

def model_train_multi(train_data, val_data, epochs, learning_rate, log_file, result_dir):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = UNet(input_channels=3, output_channels=3).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    with open(log_file, mode='a', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["Epoch", "Train Loss", "Validation Loss", "IoU", "Dice Score", "Time (s)", "Learning Rate", "GPU Memory (MB)"])

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        start_time = time.perf_counter()

        for images, masks in train_data:
            images = images.clone().detach().to(device, dtype=torch.float32)
            masks = masks.clone().detach().to(device, dtype=torch.long).squeeze(1)  # âœ… ë³€í™˜

            optimizer.zero_grad()  # âœ… ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™” ì¶”ê°€
            outputs = model(images)
            loss = criterion(outputs, masks)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        avg_train_loss = running_loss / len(train_data)

        model.eval()
        val_loss = 0.0
        iou_scores = []
        dice_scores = []

        with torch.no_grad():
            for images, masks in val_data:
                images = images.to(device)
                masks = masks.to(device, dtype=torch.long).squeeze(1)  # âœ… ì •ìˆ˜í˜• ë³€í™˜

                outputs = model(images)
                loss = criterion(outputs, masks)
                val_loss += loss.item()

                iou = compute_iou(outputs, masks)
                dice = compute_dice(outputs, masks)
                iou_scores.append(iou)
                dice_scores.append(dice)

        avg_val_loss = val_loss / len(val_data)
        avg_iou = np.mean(iou_scores)
        avg_dice = np.mean(dice_scores)
        elapsed_time = time.perf_counter() - start_time
        current_lr = optimizer.param_groups[0]['lr']
        gpu_memory = torch.cuda.memory_allocated(device) / 1024 ** 2  # MB ë‹¨ìœ„

        with open(log_file, mode='a', newline='') as file:
            writer = csv.writer(file)
            writer.writerow([epoch+1, avg_train_loss, avg_val_loss, avg_iou, avg_dice, elapsed_time, current_lr, gpu_memory])

        print(f"Epoch [{epoch+1}/{epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | IoU: {avg_iou:.4f} | Dice: {avg_dice:.4f} | Time: {elapsed_time:.2f}s | LR: {current_lr:.6f} | GPU: {gpu_memory:.2f}MB")

    save_model(model, epochs, result_dir)
    print("Model saved!")
    print("Training complete!")

# âœ… IoU & Dice Score ê³„ì‚° í•¨ìˆ˜


# âœ… IoU & Dice Score ê³„ì‚° í•¨ìˆ˜
def compute_iou_test(preds, targets):
    intersection = np.logical_and(preds, targets).sum()
    union = np.logical_or(preds, targets).sum()
    return intersection / union if union > 0 else 1.0

def compute_dice_test(preds, targets):
    intersection = np.logical_and(preds, targets).sum()
    return (2. * intersection) / (preds.sum() + targets.sum()) if (preds.sum() + targets.sum()) > 0 else 1.0

# âœ… ì´ë¯¸ì§€ ì €ì¥ í•¨ìˆ˜ (IoU ì‹œê°í™” + ë²”ë¡€ ì¶”ê°€)
def save_result_image(idx, og, unet, target, p, iou_score, dice_score, save_path):
    fig, axs = plt.subplots(1, 4, figsize=(20, 12))

    # âœ… Ground Truth (ì •ë‹µ ë§ˆìŠ¤í¬) â†’ 0ë²ˆ ìœ„ì¹˜
    axs[0].imshow(target, cmap="gray")
    axs[0].set_title("Ground Truth")
    axs[0].axis("off")

    # âœ… IoU ì‹œê°í™” â†’ 1ë²ˆ ìœ„ì¹˜
    if target.ndim == 3 and target.shape[-1] == 1:
        target = target.squeeze(-1)  # (H, W, 1) â†’ (H, W)

    intersection = np.logical_and(unet, target)
    union = np.logical_or(unet, target)

    iou_visual = np.zeros((*unet.shape, 3), dtype=np.uint8)  # (H, W, 3)
    iou_visual[target.astype(bool)] = [0, 255, 0]  # GT â†’ ì´ˆë¡ìƒ‰
    iou_visual[unet.astype(bool)] = [0, 0, 255]  # ì˜ˆì¸¡ â†’ íŒŒë€ìƒ‰
    iou_visual[intersection.astype(bool)] = [255, 255, 255]  # ê²¹ì¹˜ëŠ” ë¶€ë¶„ â†’ í°ìƒ‰

    axs[1].imshow(iou_visual)
    axs[1].set_title(f"IoU Visualization {idx}\nIoU: {iou_score:.4f} | Dice: {dice_score:.4f}")
    axs[1].axis("off")

    # âœ… ì›ë³¸ ì´ë¯¸ì§€ â†’ 2ë²ˆ ìœ„ì¹˜
    axs[2].imshow(og)
    axs[2].set_title(f"Original {idx}")
    axs[2].axis("off")

    # âœ… ì˜ˆì¸¡ ë§ˆìŠ¤í¬ â†’ 3ë²ˆ ìœ„ì¹˜
    axs[3].imshow(unet, cmap="gray")
    axs[3].set_title(f"U-Net Prediction (p > {p})")
    axs[3].axis("off")

    # âœ… ë²”ë¡€ ì¶”ê°€ (Green = GT, Blue = Prediction, White = Intersection)
    green_patch = mpatches.Patch(color='green', label='Ground Truth (GT)')
    blue_patch = mpatches.Patch(color='blue', label='Predicted Mask')
    white_patch = mpatches.Patch(color='white', label='Intersection (IoU)')

    # âœ… ë²”ë¡€ë¥¼ figure ì „ì²´ì— ì¶”ê°€ (ì¢Œí•˜ë‹¨ fig ë°–ì— ìœ„ì¹˜)
    legend_fig = fig.legend(
        handles=[green_patch, blue_patch, white_patch],
        loc='lower left',  # ì™¼ìª½ ì•„ë˜ (fig ë°”ê¹¥ìª½)
        bbox_to_anchor=(-0.05, -0.05),  # fig ë°”ê¹¥ìª½ ìœ„ì¹˜ ì¡°ì • (x, y)
        fontsize=12,
        framealpha=0.7,  # íˆ¬ëª…ë„ ì„¤ì •
        edgecolor="black"  # í…Œë‘ë¦¬ ìƒ‰ìƒ ì¶”ê°€
    )

    # âœ… ì´ë¯¸ì§€ ì €ì¥ (IoU & Dice Score í¬í•¨)
    plt.savefig(save_path, bbox_inches='tight', dpi=300)
    plt.close()

def save_result_image2(idx, og, unet, p, save_path):
    fig, axs = plt.subplots(1, 2, figsize=(20, 12))


    # âœ… ì›ë³¸ ì´ë¯¸ì§€ â†’ 2ë²ˆ ìœ„ì¹˜
    axs[0].imshow(og)
    axs[0].set_title(f"Original {idx}")
    axs[0].axis("off")

    # âœ… ì˜ˆì¸¡ ë§ˆìŠ¤í¬ â†’ 3ë²ˆ ìœ„ì¹˜
    axs[1].imshow(unet, cmap="gray")
    axs[1].set_title(f"U-Net Prediction (p > {p})")
    axs[1].axis("off")

    # âœ… ì´ë¯¸ì§€ ì €ì¥ (IoU & Dice Score í¬í•¨)
    plt.savefig(save_path, bbox_inches='tight', dpi=300)
    plt.close()
def save_result_image3(idx, og, unet, save_path):
    fig, axs = plt.subplots(1, 2, figsize=(20, 12))


    # âœ… ì›ë³¸ ì´ë¯¸ì§€ â†’ 2ë²ˆ ìœ„ì¹˜
    axs[0].imshow(og)
    axs[0].set_title(f"Original {idx}")
    axs[0].axis("off")

    # âœ… ì˜ˆì¸¡ ë§ˆìŠ¤í¬ â†’ 3ë²ˆ ìœ„ì¹˜
    axs[1].imshow(unet, cmap="gray")
    axs[1].set_title(f"U-Net Prediction")
    axs[1].axis("off")

    # âœ… ì´ë¯¸ì§€ ì €ì¥ (IoU & Dice Score í¬í•¨)
    plt.savefig(save_path, bbox_inches='tight', dpi=300)
    plt.close()
# âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def test_data_load(images_test):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    images_test_torch = torch.tensor(images_test, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0
    images_test_torch = images_test_torch.to(device)
    return images_test_torch

# âœ… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë° ê²°ê³¼ ì €ì¥ í•¨ìˆ˜
# âœ… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë° ê²°ê³¼ ì €ì¥ í•¨ìˆ˜
def model_test(test_data, masks_test, images_test, epochs, Threshold, result_dir):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = UNet(input_channels=3, output_channels=1).to(device)
    load_model(model, epochs, result_dir)

    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜
    model.eval()

    # ëª¨ë¸ ì˜ˆì¸¡
    with torch.no_grad():
        unet_predict = model(test_data)
        unet_predict = torch.sigmoid(unet_predict)  # BCE Loss ì‚¬ìš© ì‹œ í•„ìš”

    # NumPy ë³€í™˜
    unet_predict = unet_predict.cpu().numpy().squeeze(1)  # (batch, 1, H, W) â†’ (batch, H, W)

    # Threshold ì ìš©
    r_values = Threshold
    unet_predictions = [(unet_predict > r).astype(np.uint8) for r in r_values]

    # CSV ì €ì¥ íŒŒì¼ ìƒì„±
    csv_file = os.path.join(result_dir, "test_results.csv")
    with open(csv_file, mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["Index", "Threshold", "IoU", "Dice Score"])

        for idx in range(len(unet_predict)):
            for i, r in enumerate(r_values):
                iou = compute_iou_test(unet_predictions[i][idx], masks_test[idx])
                dice = compute_dice_test(unet_predictions[i][idx], masks_test[idx])

                writer.writerow([idx, r, round(iou, 4), round(dice, 4)])

                save_path = os.path.join(result_dir, f"result_{idx}_threshold_{r}.png")
                save_result_image(idx, images_test[idx], unet_predictions[i][idx], masks_test[idx], r, iou, dice, save_path)
                print(f"[Index {idx}, Threshold {r}] IoU: {iou:.4f}, Dice Score: {dice:.4f}")

    np.save(os.path.join(result_dir, "unet_predictions.npy"), unet_predict)
    del model
    torch.cuda.empty_cache()
    print(f"âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ! í´ë”: {result_dir}")
#1ë ˆì´ì–´ 1ì¥
def model_test2(test_data, images_test, epochs, Threshold, model_dir,result_dir):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = UNet(input_channels=3, output_channels=1).to(device)
    load_model(model, epochs, model_dir)

    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜
    model.eval()

    # ëª¨ë¸ ì˜ˆì¸¡
    with torch.no_grad():
        unet_predict = model(test_data)
        unet_predict = torch.sigmoid(unet_predict)  # BCE Loss ì‚¬ìš© ì‹œ í•„ìš”

    # NumPy ë³€í™˜
    unet_predict = unet_predict.cpu().numpy().squeeze(1)  # (batch, 1, H, W) â†’ (batch, H, W)

    # Threshold ì ìš©
    r_values = Threshold
    unet_predictions = [(unet_predict > r).astype(np.uint8) for r in r_values]

    # CSV ì €ì¥ íŒŒì¼ ìƒì„±
    csv_file = os.path.join(result_dir, "test_results.csv")
    with open(csv_file, mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["Index", "Threshold", "IoU", "Dice Score"])

        for idx in range(len(unet_predict)):
            for i, r in enumerate(r_values):

                writer.writerow([idx, r])

                save_path = os.path.join(result_dir, f"result_{idx}_threshold_{r}.png")
                save_result_image2(idx, images_test[idx], unet_predictions[i][idx], r, save_path)
                print(f"[Index {idx}, Threshold {r}]")

    np.save(os.path.join(result_dir, "unet_predictions.npy"), unet_predict)
    del model
    torch.cuda.empty_cache()
    print(f"âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ! í´ë”: {result_dir}")

def load_data2(images_dir, image_size=512, test_size=0.2, val_size=0.2):
    """
    ì´ë¯¸ì§€ ë° ë§ˆìŠ¤í¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , Train/Validation/Test ë°ì´í„°ë¡œ ë¶„í• í•˜ëŠ” í•¨ìˆ˜

    Args:
        images_dir (str): ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
        masks_dir (str): ë§ˆìŠ¤í¬ í´ë” ê²½ë¡œ
        image_size (int, optional): ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸ê°’: 512)
        test_size (float, optional): Test ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2)
        val_size (float, optional): Train ë°ì´í„°ì—ì„œ Validation ë°ì´í„°ë¡œ ì‚¬ìš©í•  ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2)

    Returns:
        Tuple: (images_train, images_val, images_test, masks_train, masks_val, masks_test)
    """
    images_listdir = sorted(os.listdir(images_dir))

    print(f"ì´ ì´ë¯¸ì§€ ê°œìˆ˜: {len(images_listdir)}")

    # ì´ë¯¸ì§€ ë° ë§ˆìŠ¤í¬ ë°ì´í„° ë¡œë“œ
    images = []
    for j, file in enumerate(images_listdir):
        try:
            image = cv2.imread(os.path.join(images_dir, file))
            image = cv2.resize(image, (image_size, image_size))
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # RGB ë³€í™˜
            images.append(image)

        except Exception as e:
            print(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {file} - {e}")
            continue

    images = np.array(images, dtype=np.uint8)

    print(f"ë¡œë“œëœ ì´ë¯¸ì§€ í˜•íƒœ: {images.shape}")

    print(f"Test: {images.shape}")
    return images

def with_log(epochs, learning_rate, batch_size, apply_aug: bool, augmentation_factor,
             images_dir, masks_dir, image_size, test_size, val_size, timestamp, result_dir):

    log_file = f"{result_dir}/train_log_{epochs}epochs_{timestamp}.csv"
    with open(log_file, mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['time:', timestamp, 'epochs:', epochs, 'learning_rate:', learning_rate,
                         'batch_size:', batch_size, 'Augmentation:', apply_aug, 'augmentation_factor:', augmentation_factor,
                         'images_dir:', images_dir, 'masks_dir:', masks_dir, 'image_size:', image_size,
                         'Train:Test:Val :', 1 - test_size, ':', test_size, ':', val_size])

        if apply_aug:
            writer.writerow(['Augmentation Applied', 'Transformations:', get_augmentation().__repr__()])

    # âœ… ë°ì´í„° ë¡œë“œ
    images_train, images_val, images_test, masks_train, masks_val, masks_test = load_data_multi(
        images_dir, masks_dir, image_size, test_size, val_size
    )

    # âœ… DataLoader ìƒì„± (Augmentation ë°˜ì˜)
    train_loader = train_data_load(images_train, masks_train, batch_size, apply_aug, augmentation_factor)
    val_loader = val_data_load(images_val, masks_val, batch_size, apply_aug=False)  # ğŸš€ Validationì—ë„ ì ìš© ê°€ëŠ¥

    # âœ… ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
    model_train_3(train_loader, val_loader, epochs, learning_rate, log_file,result_dir)

def model_test3(test_data, images_test, epochs, model_dir, result_dir):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = UNet(input_channels=3, output_channels=3).to(device)
    load_model(model, epochs, model_dir)

    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜
    model.eval()

    # ëª¨ë¸ ì˜ˆì¸¡
    with torch.no_grad():
        unet_predict = model(test_data)
        unet_predict = torch.softmax(unet_predict, dim=1)  # ë‹¤ì¤‘ í´ë˜ìŠ¤ ì˜ˆì¸¡ì„ ìœ„í•œ softmax ì ìš©

    # NumPy ë³€í™˜
    print('unet_predict.shape', unet_predict.shape)
    unet_predict = torch.argmax(unet_predict, dim=1).cpu().numpy()  # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ë¥¼ ì„ íƒ

    # CSV ì €ì¥ íŒŒì¼ ìƒì„±
    csv_file = os.path.join(result_dir, "test_results.csv")
    with open(csv_file, mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["Index", "IoU", "Dice Score"])  # Threshold ì œê±°

        for idx in range(len(unet_predict)):
            writer.writerow([idx])  # Threshold ì—†ì´ ì €ì¥

            save_path = os.path.join(result_dir, f"result_{idx}.png")
            save_result_image3(idx, images_test[idx], unet_predict[idx], save_path)
            print(f"[Index {idx}]")

    np.save(os.path.join(result_dir, "unet_predictions.npy"), unet_predict)
    del model
    torch.cuda.empty_cache()
    print(f"âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ! í´ë”: {result_dir}")


# # ğŸ”¹ í•™ìŠµëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
# timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
# images_dir = "./testdata/images"
# masks_dir = "./testdata/masks"
# batch_size = 16
# epochs = 200
# learning_rate = 0.0001
# image_size = 512
# test_size =0.2
# val_size = 0.2
# Augmentation = True
# augmentation_factor = 10
#
#
# # âœ… ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ í´ë” ìƒì„±
# result_dir = f"./unet/test_results{timestamp}"
# os.makedirs(result_dir, exist_ok=True)
#
# # ëª¨ë¸ í•™ìŠµ
# with_log(epochs, learning_rate,batch_size,Augmentation,augmentation_factor,images_dir,masks_dir,image_size, test_size, val_size,timestamp,result_dir)
#
#
# # âœ… ë°ì´í„° ë¡œë“œ
# images_train, images_val, images_test, masks_train, masks_val, masks_test = load_data(images_dir, masks_dir, image_size, test_size, val_size)

# # âœ… Augmentation ì¼œê³  ì‹¤í–‰
# visualize_augmentation(images_train, masks_train, apply_aug=True, num_samples=3)
#
#
# # âœ… Augmentation ë„ê³  ì‹¤í–‰
# visualize_augmentation(images_train, masks_train, apply_aug=False, num_samples=3)


# # âœ… í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ë°˜ì˜)
# Threshold = [0.4, 0.5, 0.6, 0.7]
# model_test(test_data_load(images_test), masks_test, images_test, epochs, Threshold, result_dir)
# Threshold = [0.45, 0.55, 0.65, 0.75]
# model_test(test_data_load(images_test), masks_test, images_test, epochs, Threshold, result_dir)