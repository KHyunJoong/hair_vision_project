
import os
import csv
import cv2
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import torch.optim as optim
class ConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ConvBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = F.relu(x)
        x = self.conv2(x)
        x = self.bn2(x)
        x = F.relu(x)
        return x

class EncoderBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(EncoderBlock, self).__init__()
        self.conv = ConvBlock(in_channels, out_channels)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

    def forward(self, x):
        skip = self.conv(x)
        pool = self.pool(skip)
        return skip, pool

class DecoderBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DecoderBlock, self).__init__()
        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)
        self.conv = ConvBlock(out_channels * 2, out_channels)

    def forward(self, x, skip):
        x = self.upconv(x)
        x = torch.cat([x, skip], dim=1)
        x = self.conv(x)
        return x

class UNet(nn.Module):
    def __init__(self, input_channels=3, output_channels=1):
        super(UNet, self).__init__()
        self.encoder1 = EncoderBlock(input_channels, 64)
        self.encoder2 = EncoderBlock(64, 128)
        self.encoder3 = EncoderBlock(128, 256)
        self.encoder4 = EncoderBlock(256, 512)

        self.bridge = ConvBlock(512, 1024)

        self.decoder1 = DecoderBlock(1024, 512)
        self.decoder2 = DecoderBlock(512, 256)
        self.decoder3 = DecoderBlock(256, 128)
        self.decoder4 = DecoderBlock(128, 64)

        self.final_conv = nn.Conv2d(64, output_channels, kernel_size=1)

    def forward(self, x):
        s1, p1 = self.encoder1(x)
        s2, p2 = self.encoder2(p1)
        s3, p3 = self.encoder3(p2)
        s4, p4 = self.encoder4(p3)

        b = self.bridge(p4)

        d1 = self.decoder1(b, s4)
        d2 = self.decoder2(d1, s3)
        d3 = self.decoder3(d2, s2)
        d4 = self.decoder4(d3, s1)

        outputs = torch.sigmoid(self.final_conv(d4))
        return outputs
def load_model(model, epochs,result_dir):
    path=f"{result_dir}/unet_model_{epochs}.pth"
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.load_state_dict(torch.load(path, map_location=device))
    model.to(device)
    print(f"âœ… ëª¨ë¸ì´ ë¶ˆëŸ¬ì™€ì¡ŒìŠµë‹ˆë‹¤: {path}")

def load_data2(images_dir, image_size=512, test_size=0.2, val_size=0.2):
    """
    ì´ë¯¸ì§€ ë° ë§ˆìŠ¤í¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , Train/Validation/Test ë°ì´í„°ë¡œ ë¶„í• í•˜ëŠ” í•¨ìˆ˜

    Args:
        images_dir (str): ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
        masks_dir (str): ë§ˆìŠ¤í¬ í´ë” ê²½ë¡œ
        image_size (int, optional): ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸ê°’: 512)
        test_size (float, optional): Test ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2)
        val_size (float, optional): Train ë°ì´í„°ì—ì„œ Validation ë°ì´í„°ë¡œ ì‚¬ìš©í•  ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2)

    Returns:
        Tuple: (images_train, images_val, images_test, masks_train, masks_val, masks_test)
    """
    images_listdir = sorted(os.listdir(images_dir))

    print(f"ì´ ì´ë¯¸ì§€ ê°œìˆ˜: {len(images_listdir)}")

    # ì´ë¯¸ì§€ ë° ë§ˆìŠ¤í¬ ë°ì´í„° ë¡œë“œ
    images = []
    for j, file in enumerate(images_listdir):
        try:
            image = cv2.imread(os.path.join(images_dir, file))
            image = cv2.resize(image, (image_size, image_size))
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # RGB ë³€í™˜
            images.append(image)

        except Exception as e:
            print(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {file} - {e}")
            continue

    images = np.array(images, dtype=np.uint8)

    print(f"ë¡œë“œëœ ì´ë¯¸ì§€ í˜•íƒœ: {images.shape}")

    print(f"Test: {images.shape}")
    return images

def save_result_image2(idx, og, unet, p, save_path):
    fig, axs = plt.subplots(1, 2, figsize=(20, 12))


    # âœ… ì›ë³¸ ì´ë¯¸ì§€ â†’ 2ë²ˆ ìœ„ì¹˜
    axs[0].imshow(og)
    axs[0].set_title(f"Original {idx}")
    axs[0].axis("off")

    # âœ… ì˜ˆì¸¡ ë§ˆìŠ¤í¬ â†’ 3ë²ˆ ìœ„ì¹˜
    axs[1].imshow(unet, cmap="gray")
    axs[1].set_title(f"U-Net Prediction (p > {p})")
    axs[1].axis("off")

    # âœ… ì´ë¯¸ì§€ ì €ì¥ (IoU & Dice Score í¬í•¨)
    plt.savefig(save_path, bbox_inches='tight', dpi=300)
    plt.close()

def test_data_load(images_test):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    images_test_torch = torch.tensor(images_test, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0
    images_test_torch = images_test_torch.to(device)
    return images_test_torch

def model_test2(test_data, images_test, epochs, Threshold, model_dir,result_dir):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = UNet(input_channels=3, output_channels=1).to(device)
    load_model(model, epochs, model_dir)

    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜
    model.eval()

    # ëª¨ë¸ ì˜ˆì¸¡
    with torch.no_grad():
        unet_predict = model(test_data)
        unet_predict = torch.sigmoid(unet_predict)  # BCE Loss ì‚¬ìš© ì‹œ í•„ìš”

    # NumPy ë³€í™˜
    unet_predict = unet_predict.cpu().numpy().squeeze(1)  # (batch, 1, H, W) â†’ (batch, H, W)

    # Threshold ì ìš©
    r_values = Threshold
    unet_predictions = [(unet_predict > r).astype(np.uint8) for r in r_values]

    # CSV ì €ì¥ íŒŒì¼ ìƒì„±
    csv_file = os.path.join(result_dir, "test_results.csv")
    with open(csv_file, mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["Index", "Threshold", "IoU", "Dice Score"])

        for idx in range(len(unet_predict)):
            for i, r in enumerate(r_values):

                writer.writerow([idx, r])
                above_threshold = np.sum(unet_predictions[i][idx] > 0)  # 1ë¡œ ë³€í™˜ëœ í”½ì…€ ê°œìˆ˜
                below_threshold = np.sum(unet_predictions[i][idx] == 0) # 0ì¸ í”½ì…€ ê°œìˆ˜


                save_path = os.path.join(result_dir, f"result_{idx}_threshold_{r}.png")
                save_result_image2(idx, images_test[idx], unet_predictions[i][idx], r, save_path)
                print(f"[Index {idx}, Threshold {r}]")
                print(f"[Index {idx}, Threshold {r}] Above: {above_threshold}, Below: {below_threshold}")
    np.save(os.path.join(result_dir, "unet_predictions.npy"), unet_predict)
    del model
    torch.cuda.empty_cache()
    print(f"âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ! í´ë”: {result_dir}")
    return above_threshold + below_threshold, above_threshold
images_dir = "./datasets/hair/images/validation3"
model_dir = "./unet/test_results2025-03-08_10-22-17"
result_dir = "./unet/test3"
epochs = 200
Threshold = [0.65]
image_size = 512
import torch
import torch.quantization

# ğŸ”¹ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_path = f"{model_dir}/unet_model_{epochs}.pth"

# ğŸ”¹ ì›ë³¸ ëª¨ë¸ ë¡œë“œ
model = UNet(input_channels=3, output_channels=1)
model.load_state_dict(torch.load(model_path, map_location=device))
model.to(device)
model.eval()

# ğŸ”¹ ë™ì  ì–‘ìí™” ì ìš© (Linear ë ˆì´ì–´ë§Œ INT8 ë³€í™˜ ê°€ëŠ¥)
quantized_model = torch.quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8  # Linear ë¶€ë¶„ë§Œ INT8 ë³€í™˜
)

# ğŸ”¹ ì–‘ìí™”ëœ ëª¨ë¸ ì €ì¥
quantized_model_path = f"{result_dir}/unet_model_{epochs}_dynamic_quantized.pth"
torch.save(quantized_model.state_dict(), quantized_model_path)

print(f"âœ… ë™ì  ì–‘ìí™” ì™„ë£Œ! ì €ì¥ëœ ê²½ë¡œ: {quantized_model_path}")

# âœ… ë°ì´í„° ë¡œë“œ
images_test= load_data2(images_dir, image_size)
model_test2(test_data_load(images_test), images_test, epochs,Threshold, model_dir, result_dir)

#%%
import torch
import onnx
print("ONNX ë²„ì „:", onnx.__version__)
# ğŸ”¹ ì–‘ìí™”ëœ ëª¨ë¸ ë¡œë“œ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
quantized_model_path = f"{result_dir}/unet_model_{epochs}_dynamic_quantized.pth"

# ğŸ”¹ ì›ë³¸ ëª¨ë¸ ì •ì˜
model = UNet(input_channels=3, output_channels=1)
model.load_state_dict(torch.load(quantized_model_path, map_location=device))
model.to(device)
model.eval()

# ğŸ”¹ ë”ë¯¸ ì…ë ¥ ìƒì„± (ì…ë ¥ í¬ê¸°: 1x3x512x512)
dummy_input = torch.randn(1, 3, 512, 512).to(device)

# ğŸ”¹ ONNX ë³€í™˜ ì‹¤í–‰
onnx_path = f"{result_dir}/unet_model_{epochs}_dynamic_quantized.onnx"

torch.onnx.export(
    model,
    dummy_input,
    onnx_path,
    opset_version=12,  # ìµœì‹  ONNX ë²„ì „ ì‚¬ìš©
    export_params=True,  # í•™ìŠµëœ ê°€ì¤‘ì¹˜ í¬í•¨
    do_constant_folding=True,  # ìƒìˆ˜ í´ë”© ìµœì í™”
    input_names=["input"],
    output_names=["output"]
)

print(f"âœ… ONNX ë³€í™˜ ì™„ë£Œ! ì €ì¥ëœ ê²½ë¡œ: {onnx_path}")

import tensorflow as tf
from onnx_tf.backend import prepare


# ğŸ”¹ ONNX ëª¨ë¸ ë¡œë“œ
onnx_model_path = f"{result_dir}/unet_model_{epochs}_dynamic_quantized.onnx"
onnx_model = onnx.load(onnx_model_path)

# âœ… `tensorflow-addons` ì—†ì´ ë³€í™˜í•˜ëŠ” ì„¤ì • ì ìš©
tf_rep = prepare(onnx_model, strict=False)  # strict=False ì˜µì…˜ ì¶”ê°€

# ğŸ”¹ TensorFlow ëª¨ë¸ ì €ì¥
tf_model_path = f"{result_dir}/unet_model_{epochs}_dynamic_quantized_tf"
tf_rep.export_graph(tf_model_path)

print(f"âœ… ONNX â†’ TensorFlow ë³€í™˜ ì™„ë£Œ! ì €ì¥ëœ ê²½ë¡œ: {tf_model_path}")

# ğŸ”¹ TensorFlow Lite ë³€í™˜ê¸° ë¡œë“œ
converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)

# ğŸ”¹ ê¸°ë³¸ ìµœì í™” ì ìš© (ì–‘ìí™” í¬í•¨ ê°€ëŠ¥)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

# ğŸ”¹ TFLite ë³€í™˜ ì‹¤í–‰
tflite_model = converter.convert()

# ğŸ”¹ ëª¨ë¸ ì €ì¥
tflite_model_path = f"{result_dir}/unet_model_{epochs}_dynamic_quantized.tflite"
with open(tflite_model_path, "wb") as f:
    f.write(tflite_model)

print(f"âœ… TensorFlow Lite ë³€í™˜ ì™„ë£Œ! ì €ì¥ëœ ê²½ë¡œ: {tflite_model_path}")
import torch
import onnx
import tensorflow as tf
from onnx_tf.backend import prepare

# ğŸ”¹ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_path = f"{model_dir}/unet_model_{epochs}.pth"

# ğŸ”¹ ì›ë³¸ ëª¨ë¸ ë¡œë“œ
model = UNet(input_channels=3, output_channels=1)
model.load_state_dict(torch.load(model_path, map_location=device))
model.to(device)
model.eval()

# ğŸ”¹ ë™ì  ì–‘ìí™” ì ìš©
quantized_model = torch.quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8  # Linear ë¶€ë¶„ë§Œ INT8 ë³€í™˜
)

# ğŸ”¹ TorchScript ë³€í™˜ í›„ ì €ì¥
scripted_model = torch.jit.trace(quantized_model, torch.randn(1, 3, 512, 512).to(device))
quantized_model_path = f"{result_dir}/unet_model_{epochs}_dynamic_quantized.pt"
torch.jit.save(scripted_model, quantized_model_path)

print(f"âœ… ë™ì  ì–‘ìí™” ì™„ë£Œ! ì €ì¥ëœ ê²½ë¡œ: {quantized_model_path}")

# ğŸ”¹ ONNX ë³€í™˜ ì‹¤í–‰
onnx_path = f"{result_dir}/unet_model_{epochs}_dynamic_quantized.onnx"
dummy_input = torch.randn(1, 3, 512, 512).to(device)

torch.onnx.export(
    scripted_model,  # âœ… TorchScript ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜
    dummy_input,
    onnx_path,
    opset_version=11,  # âœ… í˜¸í™˜ì„± ë¬¸ì œ ë°©ì§€
    export_params=True,
    do_constant_folding=True,
    input_names=["input"],
    output_names=["output"]
)

print(f"âœ… ONNX ë³€í™˜ ì™„ë£Œ! ì €ì¥ëœ ê²½ë¡œ: {onnx_path}")

# ğŸ”¹ ONNX â†’ TensorFlow ë³€í™˜
onnx_model = onnx.load(onnx_path)
tf_rep = prepare(onnx_model)
tf_model_path = f"{result_dir}/unet_model_{epochs}_dynamic_quantized_tf"
tf_rep.export_graph(tf_model_path)

print(f"âœ… ONNX â†’ TensorFlow ë³€í™˜ ì™„ë£Œ! ì €ì¥ëœ ê²½ë¡œ: {tf_model_path}")

# ğŸ”¹ TensorFlow Lite ë³€í™˜
converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)

# âœ… ë³€í™˜ ì˜¤ë¥˜ ë°©ì§€ ì˜µì…˜ ì¶”ê°€
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,  # ì¼ë°˜ ì—°ì‚°
    tf.lite.OpsSet.SELECT_TF_OPS  # TensorFlow ì—°ì‚° í¬í•¨
]

# âœ… ì–‘ìí™” ì ìš©
converter.optimizations = [tf.lite.Optimize.DEFAULT]

# âœ… TensorFlow Lite ë³€í™˜ ì‹¤í–‰
tflite_model = converter.convert()

# âœ… ëª¨ë¸ ì €ì¥
tflite_model_path = f"{result_dir}/unet_model_{epochs}_dynamic_quantized.tflite"
with open(tflite_model_path, "wb") as f:
    f.write(tflite_model)

print(f"âœ… TensorFlow Lite ë³€í™˜ ì™„ë£Œ! ì €ì¥ëœ ê²½ë¡œ: {tflite_model_path}")
